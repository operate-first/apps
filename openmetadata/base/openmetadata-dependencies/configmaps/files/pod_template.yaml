apiVersion: v1
kind: Pod
metadata:
  name: dummy-name
  labels:
    app: airflow
    component: scheduler
spec:
  restartPolicy: Never
  serviceAccountName: airflow
  shareProcessNamespace: false
  nodeSelector:
    {}
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - airflow
          topologyKey: kubernetes.io/hostname
  tolerations:
    []
  containers:
    - name: base
      image: quay.io/os-climate/ingestion:0.13.1.trino.320
      imagePullPolicy: IfNotPresent
      envFrom:
        - secretRef:
            name: openmetadata-dependencies-config-envs
        - configMapRef:
            name: openmetadata-dependencies-config-envs
      env:

        ## KubernetesExecutor Pods use LocalExecutor internally
        - name: AIRFLOW__CORE__EXECUTOR
          value: LocalExecutor
        - name: DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: airflow-mysql-secrets
              key: airflow-mysql-password
        - name: CONNECTION_CHECK_MAX_COUNT
          value: "20"
      ports: []
      command: []
      args: []
      volumeMounts:
        - name: dags-data
          mountPath: /opt/airflow/dags
        - name: logs-data
          mountPath: /opt/airflow/logs
  volumes:
    - name: dags-data
      persistentVolumeClaim:
        claimName: airflow-dags
    - name: logs-data
      persistentVolumeClaim:
        claimName: airflow-logs
